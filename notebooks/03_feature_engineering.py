import pandas as pd
import numpy as np
import os
from sklearn.feature_selection import VarianceThreshold
from sklearn.preprocessing import StandardScaler

# ğŸ“ Paths
gdc_dir = r"C:\Users\DELL\Desktop\Cancer Drug System\data\processed\gdc_cleaned"
gdsc_dir = r"C:\Users\DELL\Desktop\Cancer Drug System\data\processed\gdsc_cleaned"
ic50_path = r"C:\Users\DELL\Desktop\Cancer Drug System\data\processed\cellminer_cleaned\downloaded_IC50.csv"
output_dir = r"C:\Users\DELL\Desktop\Cancer Drug System\data\final"
os.makedirs(output_dir, exist_ok=True)

# âœ… Load IC50 Labels
y_df = pd.read_csv(ic50_path)
y_df.set_index(y_df.columns[0], inplace=True)
print(f"âœ… IC50 labels shape: {y_df.shape}")

# ğŸ”„ Function to load and clean features
def load_feature_data(directory):
    feature_dfs = []
    for file in os.listdir(directory):
        if file.endswith(".csv"):
            path = os.path.join(directory, file)
            df = pd.read_csv(path)

            if df.columns[0].lower() in ['id', 'sample_id', 'sampleid', 'unnamed: 0']:
                df.set_index(df.columns[0], inplace=True)
            else:
                continue

            df.index = df.index.astype(str)
            df = df.loc[~df.index.duplicated(keep='first')]
            feature_dfs.append(df)

    if not feature_dfs:
        raise ValueError(f"âŒ No valid files found in {directory}")
    
    return pd.concat(feature_dfs, axis=1, join="inner")

# âœ… Load features
print("ğŸ“¥ Loading GDC...")
gdc = load_feature_data(gdc_dir)

print("ğŸ“¥ Loading GDSC...")
gdsc = load_feature_data(gdsc_dir)

# âœ… Merge features
X_raw = pd.concat([gdc, gdsc], axis=1, join="inner")
print("âœ… Raw merged features shape:", X_raw.shape)

# âœ… Align with IC50
X = X_raw[X_raw.index.isin(y_df.index)]
y = y_df.loc[X.index]

if X.empty or y.empty:
    raise ValueError("âŒ No overlapping samples between features and IC50 data")

print(f"âœ… Aligned X shape: {X.shape}, y shape: {y.shape}")

# âœ… Scale features
X_scaled = pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns, index=X.index)

# âœ… Variance threshold
selector = VarianceThreshold(threshold=0.01)
X_high_var = pd.DataFrame(selector.fit_transform(X_scaled),
                          columns=X_scaled.columns[selector.get_support()],
                          index=X_scaled.index)
print("âœ… After variance filter:", X_high_var.shape)

# âœ… Remove NaN-heavy columns
nan_threshold = 0.2
valid_cols = X_high_var.columns[X_high_var.isnull().mean() < nan_threshold]
X_final = X_high_var[valid_cols].dropna()
y_final = y.loc[X_final.index]
print("âœ… Final features shape:", X_final.shape)

# âœ… Save outputs
X_final.to_csv(os.path.join(output_dir, "features_X.csv"))
y_final.to_csv(os.path.join(output_dir, "labels_y.csv"))
Xy_final = X_final.copy()
Xy_final[y_final.columns] = y_final
Xy_final.to_csv(os.path.join(output_dir, "Xy_final.csv"))

print("âœ… Feature engineering complete! Files saved:")
print("ğŸ“ features_X.csv")
print("ğŸ“ labels_y.csv")
print("ğŸ“ Xy_final.csv")
